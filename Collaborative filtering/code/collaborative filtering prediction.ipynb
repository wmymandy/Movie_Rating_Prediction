{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "import random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 1000209 ; Columns: 4 \n",
      "\n",
      "   movie  user  rating       date\n",
      "0   1193     1       5  978300760\n",
      "1    661     1       3  978302109\n",
      "2    914     1       3  978301968\n",
      "3   3408     1       4  978300275\n",
      "4   2355     1       5  978824291\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./ratings.dat', names=['user', 'movie', 'rating', 'date'], delimiter='::', engine= 'python')\n",
    "print('Rows:', df.shape[0], '; Columns:', df.shape[1], '\\n')\n",
    "from datetime import datetime\n",
    "#df.date = pd.to_datetime(df.date)\n",
    "df = df[['movie', 'user', 'rating', 'date']]\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data1m.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data1m.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Data Shape:  (1000209, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Input Data Shape: \",\n",
    "      data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Five Line: \n",
      "   movie  user  rating       date\n",
      "0   1193     1       5  978300760\n",
      "1    661     1       3  978302109\n",
      "2    914     1       3  978301968\n",
      "3   3408     1       4  978300275\n",
      "4   2355     1       5  978824291\n"
     ]
    }
   ],
   "source": [
    "print(\"First Five Line: \")\n",
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:  800167\n"
     ]
    }
   ],
   "source": [
    "#Create Training Set:\n",
    "train_df = data.iloc[:int(data.shape[0]*0.80)]\n",
    "print(\"Train set: \", train_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set:  200042\n"
     ]
    }
   ],
   "source": [
    "test_df = data.iloc[int(data.shape[0]*0.80) : ]\n",
    "print(\"Test set: \", test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total No of Users   : 4795\n",
      "Total No of movies  : 3685\n"
     ]
    }
   ],
   "source": [
    "print(\"Total No of Users   :\", len(np.unique(train_df.user)))\n",
    "print(\"Total No of movies  :\", len(np.unique(train_df.movie)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import cross_validate\n",
    "from surprise import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1,5))\n",
    "train_data = Dataset.load_from_df(train_df[['user', 'movie', 'rating']], reader)\n",
    "trainset = train_data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4795, 3262, 3), (4795, 2624, 4), (4795, 2628, 3)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset = list(zip(test_df.user.values, test_df.movie.values, test_df.rating.values))\n",
    "testset[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_train_test(algo, train, test):\n",
    "    print('Training the model..')\n",
    "    start =datetime.now()    \n",
    "    algo.fit(train)\n",
    "    print('Done. Time taken : {}\\n'.format(datetime.now()-start))\n",
    "    print('Evaluating the model with TRAIN data...')\n",
    "    start =datetime.now()\n",
    "    prediction_train = algo.test(train.build_testset())\n",
    "    rmse_train = accuracy.rmse(prediction_train)\n",
    "    mae_train = accuracy.mae(prediction_train)\n",
    "    print('Done. Time taken : {}\\n'.format(datetime.now()-start))\n",
    "    print('\\nEvaluating for test data...')\n",
    "    start =datetime.now()\n",
    "    prediction = algo.test(test)\n",
    "    rmse_test = accuracy.rmse(prediction)\n",
    "    mae_test = accuracy.mae(prediction)\n",
    "    print('Done. Time taken : {}\\n'.format(datetime.now()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Baseline Model ( with User and Item biases)\n",
    "from surprise import BaselineOnly\n",
    "bsl_options = {'method': 'sgd',\n",
    "               'learning_rate': .001\n",
    "               }\n",
    "bsl = BaselineOnly(bsl_options=bsl_options)\n",
    "algo.append([bsl, \"Baseline Model with User and Item Biases\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN with User User similarities\n",
    "from surprise import KNNBaseline\n",
    "sim_options = {'user_based' : True,\n",
    "               'name': 'pearson_baseline',\n",
    "               'shrinkage': 100,\n",
    "               'min_support': 2\n",
    "              } \n",
    "bsl_options = {'method': 'sgd'} \n",
    "knn_bsl_u = KNNBaseline(k=40, sim_options = sim_options, bsl_options = bsl_options)\n",
    "algo.append([knn_bsl_u, \"KNN Basline with User User Similarity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<surprise.prediction_algorithms.baseline_only.BaselineOnly at 0x20e1a366f88>,\n",
       "  'Baseline Model with User and Item Biases'],\n",
       " [<surprise.prediction_algorithms.knns.KNNBaseline at 0x20e1a36a648>,\n",
       "  'KNN Basline with User User Similarity']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN with Item Item similarities\n",
    "sim_options = {'user_based' : False,\n",
    "               'name': 'pearson_baseline',\n",
    "               'shrinkage': 100,\n",
    "               'min_support': 2\n",
    "              } \n",
    "bsl_options = {'method': 'sgd'}\n",
    "knn_bsl_m = KNNBaseline(k=40, sim_options = sim_options, bsl_options = bsl_options)\n",
    "algo.append([knn_bsl_m, \"KNN Basline with Item Item Similarity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVD - MF algorithm withuser item interactions\n",
    "from surprise import SVD\n",
    "svd = SVD(n_factors=100, biased=True, random_state=15, verbose=True)\n",
    "algo.append([svd, \"SVD model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "Model: Baseline Model with User and Item Biases\n",
      "Training the model..\n",
      "Estimating biases using sgd...\n",
      "Done. Time taken : 0:00:01.681527\n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "RMSE: 0.9013\n",
      "MAE:  0.7136\n",
      "Done. Time taken : 0:00:09.275603\n",
      "\n",
      "\n",
      "Evaluating for test data...\n",
      "RMSE: 0.9955\n",
      "MAE:  0.7868\n",
      "Done. Time taken : 0:00:03.019585\n",
      "\n",
      "==========================================================\n",
      "Model: KNN Basline with User User Similarity\n",
      "Training the model..\n",
      "Estimating biases using sgd...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done. Time taken : 0:01:18.571339\n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "RMSE: 0.5522\n",
      "MAE:  0.4267\n",
      "Done. Time taken : 0:08:07.364467\n",
      "\n",
      "\n",
      "Evaluating for test data...\n",
      "RMSE: 0.9903\n",
      "MAE:  0.7838\n",
      "Done. Time taken : 0:00:03.103025\n",
      "\n",
      "==========================================================\n",
      "Model: KNN Basline with Item Item Similarity\n",
      "Training the model..\n",
      "Estimating biases using sgd...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done. Time taken : 0:00:47.924994\n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "RMSE: 0.5682\n",
      "MAE:  0.4436\n",
      "Done. Time taken : 0:04:11.905836\n",
      "\n",
      "\n",
      "Evaluating for test data...\n",
      "RMSE: 0.9903\n",
      "MAE:  0.7838\n",
      "Done. Time taken : 0:00:02.451465\n",
      "\n",
      "==========================================================\n",
      "Model: SVD model\n",
      "Training the model..\n",
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "Done. Time taken : 0:00:43.124213\n",
      "\n",
      "Evaluating the model with TRAIN data...\n",
      "RMSE: 0.6689\n",
      "MAE:  0.5282\n",
      "Done. Time taken : 0:00:09.046964\n",
      "\n",
      "\n",
      "Evaluating for test data...\n",
      "RMSE: 0.9890\n",
      "MAE:  0.7873\n",
      "Done. Time taken : 0:00:03.142422\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for a in algo:\n",
    "    print(\"==========================================================\")\n",
    "    print(\"Model: \" + a[1])\n",
    "    evaluate_train_test(a[0], trainset, testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predction for each model\n",
    "test = train_df.sample(10)\n",
    "reader = Reader(rating_scale=(1,5))\n",
    "test_data = Dataset.load_from_df(test[['user', 'movie', 'rating']], reader)\n",
    "train = test_data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = train.build_testset()\n",
    "pred = test[['user', 'movie', 'rating']]\n",
    "l = [bsl, knn_bsl_u, knn_bsl_m, svd]\n",
    "for i in range(len(l)):\n",
    "    predictions = l[i].test(testset)\n",
    "    model_pred = pd.DataFrame([[i.uid, i.iid, i.est] for i in predictions], columns=['user', 'movie', str(i)])\n",
    "    pred = pd.merge(pred, model_pred, how='left', left_on=['user', 'movie'], right_on=['user', 'movie'])\n",
    "pred.columns = pred.columns[:3].tolist() + ['bsl', 'knn_bsl_u', 'knn_bsl_m', 'svd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>movie</th>\n",
       "      <th>rating</th>\n",
       "      <th>bsl</th>\n",
       "      <th>knn_bsl_u</th>\n",
       "      <th>knn_bsl_m</th>\n",
       "      <th>svd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1001</td>\n",
       "      <td>3745</td>\n",
       "      <td>4</td>\n",
       "      <td>3.499386</td>\n",
       "      <td>3.793326</td>\n",
       "      <td>3.737759</td>\n",
       "      <td>3.858508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4384</td>\n",
       "      <td>440</td>\n",
       "      <td>5</td>\n",
       "      <td>4.272058</td>\n",
       "      <td>4.405127</td>\n",
       "      <td>4.290638</td>\n",
       "      <td>4.214437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4064</td>\n",
       "      <td>1019</td>\n",
       "      <td>3</td>\n",
       "      <td>3.227620</td>\n",
       "      <td>3.362304</td>\n",
       "      <td>3.444051</td>\n",
       "      <td>3.512397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3461</td>\n",
       "      <td>1036</td>\n",
       "      <td>5</td>\n",
       "      <td>4.551968</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.980463</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1943</td>\n",
       "      <td>180</td>\n",
       "      <td>4</td>\n",
       "      <td>3.639637</td>\n",
       "      <td>3.460256</td>\n",
       "      <td>3.552031</td>\n",
       "      <td>3.187237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3444</td>\n",
       "      <td>471</td>\n",
       "      <td>3</td>\n",
       "      <td>3.290491</td>\n",
       "      <td>3.525312</td>\n",
       "      <td>3.367330</td>\n",
       "      <td>3.249894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4569</td>\n",
       "      <td>2826</td>\n",
       "      <td>3</td>\n",
       "      <td>3.417219</td>\n",
       "      <td>3.414261</td>\n",
       "      <td>3.406698</td>\n",
       "      <td>3.339284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>922</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>3.746115</td>\n",
       "      <td>3.827676</td>\n",
       "      <td>3.813146</td>\n",
       "      <td>4.280857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3648</td>\n",
       "      <td>849</td>\n",
       "      <td>1</td>\n",
       "      <td>2.203562</td>\n",
       "      <td>2.097621</td>\n",
       "      <td>1.972498</td>\n",
       "      <td>2.023431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1878</td>\n",
       "      <td>546</td>\n",
       "      <td>2</td>\n",
       "      <td>2.354225</td>\n",
       "      <td>2.033213</td>\n",
       "      <td>1.983627</td>\n",
       "      <td>1.682131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  movie  rating       bsl  knn_bsl_u  knn_bsl_m       svd\n",
       "0  1001   3745       4  3.499386   3.793326   3.737759  3.858508\n",
       "1  4384    440       5  4.272058   4.405127   4.290638  4.214437\n",
       "2  4064   1019       3  3.227620   3.362304   3.444051  3.512397\n",
       "3  3461   1036       5  4.551968   5.000000   4.980463  5.000000\n",
       "4  1943    180       4  3.639637   3.460256   3.552031  3.187237\n",
       "5  3444    471       3  3.290491   3.525312   3.367330  3.249894\n",
       "6  4569   2826       3  3.417219   3.414261   3.406698  3.339284\n",
       "7   922     11       4  3.746115   3.827676   3.813146  4.280857\n",
       "8  3648    849       1  2.203562   2.097621   1.972498  2.023431\n",
       "9  1878    546       2  2.354225   2.033213   1.983627  1.682131"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
